{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43d6b72f",
   "metadata": {},
   "source": [
    "## Building A Chatbot\n",
    "In this video We'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "- Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "- Agents: Build a chatbot that can take actions\n",
    "\n",
    "This video tutorial will cover the basics which will be helpful for those two more advanced topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f970fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "#from langchain_openai import ChatOpenAI\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3ed5103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001D280543D60>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001D280677E80>, model_name='Gemma2-9b-It')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(\n",
    "    model = \"Gemma2-9b-It\",\n",
    "    groq_api_key = groq_api_key,\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b7de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc77463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke('What is the capital of France?')\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f263f78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi Adekunle! It's great to meet you. As an AI engineer, you must work on some fascinating projects. What specific areas of AI are you most passionate about?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage , SystemMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Hi , my name is Adekunle and I am a AI engineer\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4353927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "result = model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi , my name is Adekunle and I am a AI engineer\"),\n",
    "        AIMessage(content= \"Hello Adekunle It's nice to meet you. \\n\\nAs an AI Engineer, what kind of projects are you working on these days? \\n\\nI'm always eager to learn more about the exciting work being done in the field of AI.\\n\"),\n",
    "        SystemMessage(content=\"Hey , what is my name and what do I do?\")\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97da10d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 88, 'total_tokens': 91, 'completion_time': 0.005454545, 'prompt_time': 0.004106151, 'queue_time': 0.156967386, 'total_time': 0.009560696}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c7021a5f-fe0c-4542-83d3-0082fda8f1f5-0', usage_metadata={'input_tokens': 88, 'output_tokens': 3, 'total_tokens': 91})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99780d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5ae82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id : str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model , get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcbd9a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable' : {'session_id' : 'chat1'}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , my name is Adekunle and I am a AI engineer\")],\n",
    "    config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48eaab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Adekunle, it's nice to meet you!\n",
      "\n",
      "That's awesome that you're an AI engineer. It's a really exciting field right now.  \n",
      "\n",
      "What kind of AI work are you involved in? \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b947fb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Adekunle. üòä  I remember that from our introduction! \\n', response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 88, 'total_tokens': 108, 'completion_time': 0.036363636, 'prompt_time': 0.004074662, 'queue_time': 0.15603068, 'total_time': 0.040438298}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e19d70cd-fb96-4446-896f-976017e6c2a8-0', usage_metadata={'input_tokens': 88, 'output_tokens': 20, 'total_tokens': 108})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name ?\")],\n",
    "    config = config\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42f9db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to know!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####Change the config---->session_id\n",
    "config1 = {'configurable' : {'session_id' : 'chat2'}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config = config1\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16d9b95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi John, it's nice to meet you! üëã \\n\\nIs there anything I can help you with today? üòä\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is John\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c05724d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is John.  \n",
      "\n",
      "I remember you told me earlier! üòÑ  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name ?\")],\n",
    "    config = config1\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab48e6",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f52e6bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate , MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\" , \"You are a helpful assistant.Amnswer all the question to the nest of your ability\"),\n",
    "        ('user' ,\"{messages}\")\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebb9e025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Adekunnle, it's nice to meet you! üëã \\n\\nHow can I help you today? üòä \\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\"messages\" : [HumanMessage(content=\"Hi , my name is Adekunnle\")]} \n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8635063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain , get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94c2c68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Yusuf, it's nice to meet you!  \\n\\nAs an AI assistant, I'm always happy to help. What can I do for you today?  \\n\\nAre you working on any interesting projects as an AI engineer?  \\n\", response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 603, 'total_tokens': 655, 'completion_time': 0.094545455, 'prompt_time': 0.02709599, 'queue_time': 0.15647148, 'total_time': 0.121641445}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2da80d6d-950b-4fea-a91e-2449b0b7bb55-0', usage_metadata={'input_tokens': 603, 'output_tokens': 52, 'total_tokens': 655})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'configurable' : {'session_id' : 'chat3'}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , my name is Yusuf and I am a AI engineer\")],\n",
    "    config = config\n",
    "    \n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "307f2571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Yusuf.  \\n\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name ?\")],\n",
    "    config = config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47cc1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "345751e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡•É‡§∑‡•ç‡§£! ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§§‡§æ‡§ì, ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å? üòä\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\" : [HumanMessage(content=\"Hi , my name is krish\")],\n",
    "        \"language\" : \"Hindi\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25d62303",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain ,\n",
    "    get_session_history,\n",
    "    input_messages_key= \"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7f433b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L\\'intelligence artificielle (IA) est un domaine de l\\'informatique qui vise √† cr√©er des machines capables d\\'ex√©cuter des t√¢ches qui n√©cessitent g√©n√©ralement l\\'intelligence humaine. \\n\\nImaginez un ordinateur qui peut apprendre, r√©soudre des probl√®mes, comprendre le langage naturel et m√™me prendre des d√©cisions comme un humain. C\\'est l\\'objectif de l\\'IA. \\n\\nIl existe plusieurs types d\\'IA, allant des syst√®mes simples qui effectuent des t√¢ches pr√©programm√©es aux syst√®mes plus avanc√©s capables d\\'apprendre √† partir de donn√©es et de s\\'adapter √† de nouvelles situations. \\n\\nVoici quelques exemples concrets d\\'applications de l\\'IA:\\n\\n* **Les assistants vocaux** comme Siri ou Alexa utilisent l\\'IA pour comprendre vos commandes et y r√©pondre.\\n* **Les syst√®mes de recommandation** sur les plateformes de streaming (Netflix, Spotify) utilisent l\\'IA pour vous proposer des films ou des chansons que vous pourriez aimer.\\n* **Les voitures autonomes** utilisent l\\'IA pour \"voir\" leur environnement, prendre des d√©cisions et naviguer sans conducteur.\\n\\nL\\'IA est un domaine en pleine √©volution avec un potentiel √©norme pour transformer notre monde. \\n\\n\\n\\nJ\\'esp√®re que cette explication est claire pour vous. Avez-vous d\\'autres questions sur l\\'IA ?\\n\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'configurable' : {'session_id' : 'chat4'}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\" : [HumanMessage(content=\"Explain artificial intelligence\")],\n",
    "        \"language\" : \"French\"\n",
    "    },\n",
    "    config = config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c822895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Krish.  üòÑ  It's nice to meet you, Krish! \\n\\n\\n\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"English\"},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c91c35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Votre nom est Krish. üòä \\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e392c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
